{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f1df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "from Bio import SeqIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db8f9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gtf(gtf_file):\n",
    "    \"\"\"\n",
    "    解析 GTF 文件中所有的 exon 记录，\n",
    "    返回一个字典：{transcript_id: [(exon_number, start, end, strand), ...]}\n",
    "    如果某个 exon 没有 exon_number，则 exon_number 设为 None。\n",
    "    \"\"\"\n",
    "    transcripts = {}\n",
    "    with open(gtf_file) as fin:\n",
    "        for line in fin:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                continue\n",
    "            fields = line.split(\"\\t\")\n",
    "            if len(fields) < 9:\n",
    "                continue\n",
    "            feature = fields[2]\n",
    "            if feature != \"exon\":\n",
    "                continue\n",
    "            try:\n",
    "                start = int(fields[3])\n",
    "                end = int(fields[4])\n",
    "            except ValueError:\n",
    "                continue\n",
    "            strand = fields[6]\n",
    "            attr_field = fields[8]\n",
    "            # 提取 transcript_id ，形如 transcript_id \"XXX\";\n",
    "            m = re.search(r'transcript_id \"([^\"]+)\"', attr_field)\n",
    "            if not m:\n",
    "                continue\n",
    "            transcript_id = m.group(1)\n",
    "            # 尝试提取 exon_number\n",
    "            m2 = re.search(r'exon_number \"([^\"]+)\"', attr_field)\n",
    "            exon_number = int(m2.group(1)) if m2 else None\n",
    "\n",
    "            exon_info = (exon_number, start, end, strand)\n",
    "            transcripts.setdefault(transcript_id, []).append(exon_info)\n",
    "    # 对每个 transcript 的 exon 按照 exon_number 排序（若 exon_number 可用，否则按 start 升序）\n",
    "    for tid in transcripts:\n",
    "        if all(x[0] is not None for x in transcripts[tid]):\n",
    "            transcripts[tid].sort(key=lambda x: x[0])\n",
    "        else:\n",
    "            transcripts[tid].sort(key=lambda x: x[1])\n",
    "    return transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "394d4dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_aligned_sequence(aligned_seq, exon_lengths):\n",
    "    \"\"\"\n",
    "    给定比对序列 aligned_seq（包含 gap '-'）以及各个 exon 的原始长度 exon_lengths（列表），\n",
    "    根据累计非 gap 字符数将 aligned_seq 分段，返回分段后的列表，每段对应一个 exon。\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "    current_segment = []\n",
    "    raw_count = 0  # 计数非 gap 字符个数\n",
    "    exon_index = 0\n",
    "    # target 为当前 exon 截取时非 gap字符的累计目标值\n",
    "    target = exon_lengths[exon_index] if exon_lengths else 0\n",
    "\n",
    "    for char in aligned_seq:\n",
    "        # 如果已经分完所有 exon，则忽略后面可能存在的多余 gap（例如末端 gap）\n",
    "        if exon_index >= len(exon_lengths):\n",
    "            break\n",
    "        current_segment.append(char)\n",
    "        if char != '-':\n",
    "            raw_count += 1\n",
    "            if raw_count == target:\n",
    "                # 到达当前 exon 的边界，保存当前 segment\n",
    "                segments.append(\"\".join(current_segment))\n",
    "                current_segment = []\n",
    "                exon_index += 1\n",
    "                if exon_index < len(exon_lengths):\n",
    "                    target += exon_lengths[exon_index]\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dfbf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(mafft_file):\n",
    "    # 读取 mafft fasta 文件\n",
    "    records = list(SeqIO.parse(mafft_file, \"fasta\"))\n",
    "    # 用于缓存各个物种对应的 GTF 解析结果，格式：{species: {transcript_id: exon_info_list}}\n",
    "    species_to_transcripts = {}\n",
    "\n",
    "    for record in records:\n",
    "        header = record.id  # 如 \"Bicyclus_anynana_Bany005764.1\"\n",
    "        # 解析 species 和 transcript_id：\n",
    "        # 假设 transcript_id 为最后一个 \"_\" 后面的部分，species 为其余部分\n",
    "        parts = header.split(\"_\")\n",
    "        if len(parts) < 2:\n",
    "            sys.stderr.write(f\"错误的 header 格式: {header}\\n\")\n",
    "            continue\n",
    "        species = \"_\".join(parts[:-1])\n",
    "        transcript_id = parts[-1]\n",
    "\n",
    "        # 加载该物种对应的 GTF 文件（只加载一次）\n",
    "        if species not in species_to_transcripts:\n",
    "            gtf_file = f\"{species}.exon.gtf\"\n",
    "            if not os.path.exists(gtf_file):\n",
    "                sys.stderr.write(f\"未找到 GTF 文件：{gtf_file}\\n\")\n",
    "                species_to_transcripts[species] = None\n",
    "            else:\n",
    "                transcripts = parse_gtf(gtf_file)\n",
    "                species_to_transcripts[species] = transcripts\n",
    "\n",
    "        # 如果未能加载 GTF，则跳过\n",
    "        if species_to_transcripts[species] is None:\n",
    "            sys.stderr.write(f\"跳过 {header}，因为找不到对应的 GTF 文件。\\n\")\n",
    "            continue\n",
    "\n",
    "        transcripts = species_to_transcripts[species]\n",
    "        if transcript_id not in transcripts:\n",
    "            sys.stderr.write(f\"在 {species}.exon.gtf 中未找到转录本 {transcript_id} 的 exon 信息\\n\")\n",
    "            continue\n",
    "\n",
    "        exons = transcripts[transcript_id]\n",
    "        # 计算各 exon 的原始长度（注意：GTF 中坐标为 1-based，长度计算公式为 end - start + 1）\n",
    "        exon_lengths = [exon[2] - exon[1] + 1 for exon in exons]\n",
    "        aligned_seq = str(record.seq)\n",
    "        segments = partition_aligned_sequence(aligned_seq, exon_lengths)\n",
    "\n",
    "        # 输出结果：先输出序列名，再逐条输出 exon 片段\n",
    "        print(f\">{header}\")\n",
    "        for i, seg in enumerate(segments, 1):\n",
    "            print(f\"exon{i}: {seg}\")\n",
    "        print()  # 空行分隔不同记录"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
